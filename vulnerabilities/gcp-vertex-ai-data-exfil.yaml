title: Vertex AI Studio data exfiltration
slug: gcp-vertex-ai-data-exfil
cves: null
affectedPlatforms:
- GCP
affectedServices:
- Vertex AI Studio
image: https://images.unsplash.com/photo-1532303517831-241791b20fb9?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D
severity: Low
discoveredBy:
  name: Johann Rehberger
  org: null
  domain: https://embracethered.com
  twitter: wunderwuzzi23
publishedAt: 2023/10/19
disclosedAt: 2023/08/30
exploitabilityPeriod: null
knownITWExploitation: false
summary: |
  In Vertex AI Studio, a Prompt Injection attack could cause the LLM to return
  markdown tags. This could have allowed an adversary whose data makes it into
  the chat context (e.g., via an uploaded file) to achieve
  exfiltration of the victimâ€™s data by rendering hyperlinks. However, the severity of this issue is low,
  as there were no integrations that could pull remote content. This means
  Indirect Prompt Injection was not possible, and it would require the victim to copy
  the malicious prompt from elsewhere. A similar issue affected Azure AI.
manualRemediation: |
  None required
detectionMethods: null
contributor: https://github.com/ramimac
references:
- https://embracethered.com/blog/posts/2023/google-gcp-generative-ai-studio-data-exfiltration-fixed/
